# K8S - Lista de Tarefas

## 1.0 DescriÃ§Ã£o

O objetivo deste projeto Ã© colocar no ar uma aplicaÃ§Ã£o de lista de tarefas. Para fazer isso criei um Cluster Kubernetes local com o **Minikube** para fins de testes.

A aplicaÃ§Ã£o contÃ©m um frontend, que irÃ¡ rodar em um pod. Na aplicaÃ§Ã£o poderemos fazer atividades bÃ¡sicas de CRUD. 

O backend da aplicaÃ§Ã£o contÃ©m uma API que desenvolvi com Java. Para mais detalhes da API acesse a docuemntaÃ§Ã£o dela.

- Link: [Lista de Tarefas - Backend](https://github.com/paulo-fabiano/lista_tarefas)

## 2.0 Requisitos

Os requisitos para montar esse ambiente foram:

- Docker
- Minikube
- Kubectl

## 3.0 ConfiguraÃ§Ã£o do Cluster

ApÃ³s instalar o **Minikube** em nosso ambiente usamos o comando para iniciar o cluster:

```
minikube start
```

VocÃª verÃ¡ uma saÃ­da parecida com estÃ¡:

```
ğŸ˜„  minikube v1.35.0 on Ubuntu 22.04 (kvm/amd64)
âœ¨  Using the docker driver based on existing profile
ğŸ‘  Starting "minikube" primary control-plane node in "minikube" cluster
ğŸšœ  Pulling base image v0.0.46 ...
ğŸ”„  Restarting existing docker container for "minikube" ...
ğŸ³  Preparing Kubernetes v1.32.0 on Docker 27.4.1 ...
ğŸ”  Verifying Kubernetes components...
    â–ª Using image registry.k8s.io/ingress-nginx/controller:v1.11.3
    â–ª Using image gcr.io/k8s-minikube/storage-provisioner:v5
    â–ª Using image registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.4
    â–ª Using image registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.4
ğŸ”  Verifying ingress addon...
ğŸŒŸ  Enabled addons: default-storageclass, storage-provisioner, ingress
ğŸ„  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
```

Com o Cluster criado, apliquei os arquivos **.yaml** para criar os Pods e os services.

- Criando Pods
  
```
kubectl apply -f deployment.yaml 
```

- Criando Services

```
kubectl apply -f services.yaml
```

Podemos ver se os Pods e os Services foram criados:

- Checando Pods
  
```
kubectl get pods
```

```
NAME                        READY   STATUS    RESTARTS   AGE
backend-6b849bbd5b-tptxn    1/1     Running   0          84m
frontend-5fd4c5dbd7-7skq8   1/1     Running   0          84m
```

- Checando Services
  
```
kubectl get services
```

```
NAME               TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE
backend-service    LoadBalancer   10.98.129.88   10.98.129.88   8080:31192/TCP   80m
frontend-service   LoadBalancer   10.99.48.25    10.99.48.25    80:32311/TCP     80m
kubernetes         ClusterIP      10.96.0.1      <none>         443/TCP          95m
```

## 4.0 ConfiguraÃ§Ã£o da AplicaÃ§Ã£o

O Frontend da aplicaÃ§Ã£o Ã© bem simples. ContÃ©m somente um HTML com algumas poucas informaÃ§Ãµes que foi desenvolvido somente para ser utilizado em conjunto com a API do projeto  [Lista de Tarefas](https://github.com/paulo-fabiano/lista_tarefas). Para fazer utilizei o **Express** do **NODE.js** para subir um servidor que irÃ¡ servir o arquivo `.html` com as funÃ§Ãµes que estÃ£o no arquivo `app.js` dentro do diretÃ³rio frontend da aplicaÃ§Ã£o.

## 5.0 ConfiguraÃ§Ã£o das Imagens Docker

HÃ¡ dois arquivos Dockerfiles que foram utilizados para gerar as respectivas imagens Docker que foram utilizadas nesse projeto.

Como o Kubernetes utiliza o registre do Docker Hub, enviei as imagens para o meu repositÃ³rio pÃºblico. Consulte as imagens atravÃ©s dos links abaixo:

- Imagem Frontend -> [pfabianofilho/front-lista-tarefas:v1]()
- Imagem Backend -> [pfabianofilho/back-lista-tarefas:v1]()

## 6.0 Funcionamento

![AplicaÃ§Ã£o Rodando](/images/image.png)

Como podemos verificar, Ã© possÃ­vel realizar as operaÃ§Ãµes bÃ¡sicas de CRUD. Perdoem o Frontend da aplicaÃ§Ã£o (rsrs), eu sou bom em muitas coisas. PorÃ©m o Frontend nÃ£o Ã© meu ponto forte. O importante Ã© que funciona nÃ©!? rsrs

## 7.0 Aprendizado

O **Minikube** nÃ£o expÃµe endereÃ§os IPs externos quando utilizamos o Service do tipo **LoadBalancer**, para que ele exponha endereÃ§os IPs para testarmos a aplicaÃ§Ã£o localmente Ã© necessÃ¡rio utilizar o comando:

```
 minikube tunnel & disown
```

Outro problema interessante que percebi Ã© que eu estava configurando no arquivo **index.html** a URL do backend como:

```
  <script>
    const BACKEND_URL = "http://backend-service:8080"; 
  </script>
```

AÃ­ comecei a enfrentar alguns erros relacionados a DNS, fiquei um tempo sem entender atÃ© compreender que quando eu clicava em `Adicionar` a tarefa o navegador enviava uma requisiÃ§Ã£o para um domÃ­nio que nÃ£o existia, e nÃ£o para o Pod do backend. Para consertar isso modifiquei o tipo do Service do backend para LoadBalancer para ele ser acessÃ­vel tambÃ©m fora do Cluster. ApÃ³s isso modifiquei a variÃ¡vel no frontend para:

```
  <script>
    const BACKEND_URL = "http://10.98.129.88:8080"; 
  </script>
```

E "vualÃ¡" (rsrs), como num passe de mÃ¡gica minha aplicaÃ§Ã£o comeÃ§ou a funcionar corretamente.

O aprendizado Ã© constante! **#rumoaelite**

## 8.0 DÃºvidas e SugestÃµes?

Entre em contato comigo via:

- [Linkedin](https://www.linkedin.com/in/paulo-fabiano)
- [Email](mailto:pfabianof@gmail.com)


